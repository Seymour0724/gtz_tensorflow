# 利用Tensorflow识别MNIST

### Softmax回归

* 它是一个线性多分类模型，实际上他是从逻辑回归上转化过来的。
* 两者之间的区别是：逻辑回归是二分类模型、softmax是多分类模型。
* Softmax函数的主要功能是将各个类别的“打分”转化成合理的概率值。

### placeholder占位符

1. 在tensorflow中，无论是占位符还是变量，它们实际上都是“Tensor”。
2. Tensor并不是数值，它只是一些我们“希望”TensorFlow系统计算的“节点”。
3. 本程序中占位符与变量是不同类型的tensor：
    （1）占位符：占位符不依赖于其他的Tensor，它的值由用户自行传递给TensorFlow，通常用来存储样本数据和标签。
               **x = tf.placeholder(tf.float32 , [None,784])**，它是用来存储训练图片数据的占位符。
               **None表示这一位的大小可以是任意的**
    （2）变量：在计算过程中可以进行改变的值，每次计算后变量的值都会被保存下来。

### softmax的交叉熵

* 对于模型输出的y 与 实际的标签y_，他们之间越相似越好，在softmax模型中，通常使用“交叉熵”损失来衡量这种相似性。
* 损失越小，输出的值与实际的值就越接近。
* 构造完损失之后，下一步就是如何优化损失，让损失减小（本程序代码中使用的是梯度下降法去优化损失）
    